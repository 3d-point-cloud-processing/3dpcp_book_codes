{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# メッシュデータ変換処理\n",
    "\n",
    "点群データからメッシュデータへの変換，およびメッシュデータから点群データへの変換について述べます．\n",
    "点群データからメッシュデータへの変換を行うアルゴリズムとしては，マーチングキューブ法が有名です．\n",
    "まずはじめに，点群データを2値のボクセルデータないし（物体表面上のボクセルが物体表面までの距離に応じた連続値である）TSDFデータに変換します．\n",
    "Open3Dでは，たとえば下記の処理で（空の）TSDFデータ`volume`を定義します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "volume = o3d.pipelines.integration.ScalableTSDFVolume(\n",
    "    voxel_length=4.0 / 512.0,\n",
    "    sdf_trunc=0.04,\n",
    "    color_type=o3d.pipelines.integration.TSDFVolumeColorType.RGB8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に，複数枚のRGBD画像とそのオドメトリを用いて，`volume`に点群データの情報を統合していきます．\n",
    "オドメトリの推定方法については`o3d_rgbd_odometry.ipynb`を参照ください．\n",
    "今回のサンプルプログラムでは，既に取得したオドメトリをファイルから読み込んで使用します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class CameraPose:\n",
    "    def __init__(self, meta, mat):\n",
    "        self.metadata = meta\n",
    "        self.pose = mat\n",
    "    def __str__(self):\n",
    "        return 'Metadata : ' + ' '.join(map(str, self.metadata)) + \"\\nPose : \\n\" + np.array_str(self.pose)\n",
    "\n",
    "def read_trajectory(filename):\n",
    "    traj = []\n",
    "    with open(filename, 'r') as f:\n",
    "        metastr = f.readline()\n",
    "        while metastr:\n",
    "            metadata = list(map(int, metastr.split()))\n",
    "            mat = np.zeros(shape=(4, 4))\n",
    "            for i in range(4):\n",
    "                matstr = f.readline()\n",
    "                mat[i] = np.fromstring(matstr, dtype=float, sep=' \\t')\n",
    "            traj.append(CameraPose(metadata, mat))\n",
    "            metastr = f.readline()\n",
    "    return traj\n",
    "\n",
    "dirname = \"../3rdparty/Open3D/examples/test_data\"\n",
    "camera_poses = read_trajectory(dirname + \"/RGBD/odometry.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで，ファイルodometry.logからオドメトリを読み込むことができました．\n",
    "次に，RGBD画像を次々に読み込み，オドメトリを用いて点群データを幾何変換しつつ，`volume`にデータを格納します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrate 0-th image into the volume.\n",
      "Integrate 1-th image into the volume.\n",
      "Integrate 2-th image into the volume.\n",
      "Integrate 3-th image into the volume.\n",
      "Integrate 4-th image into the volume.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(camera_poses)):\n",
    "    print(\"Integrate {:d}-th image into the volume.\".format(i))\n",
    "    color = o3d.io.read_image(dirname + \"/RGBD/color/{:05d}.jpg\".format(i))\n",
    "    depth = o3d.io.read_image(dirname + \"/RGBD/depth/{:05d}.png\".format(i))\n",
    "    rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "        color, depth, depth_trunc=4.0, convert_rgb_to_intensity=False)\n",
    "    volume.integrate(\n",
    "        rgbd,\n",
    "        o3d.camera.PinholeCameraIntrinsic(\n",
    "            o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault),\n",
    "        np.linalg.inv(camera_poses[i].pose))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "こうして，TSDFデータを取得することができました．\n",
    "\n",
    "ここで，マーチングキューブ法を用いてTSDFデータをメッシュデータに変換するアルゴリズムを説明します．\n",
    "マーチングキューブ法は，物体の表面が通るボクセル，すなわち今回の例ではTSDF値が$1$から$-1$までの何らかの連続値を取るようなボクセルに対して，メッシュ（等値面）を切るという方法です．\n",
    "ボクセルの$8$個の頂点それぞれが物体の内側にあるか外側にあるかを考えると，メッシュの切り方のパターンは全部で$2^8 = 256$通りとなりますが，回転対称や反転を無視すると，全パターンは$15$通りとなります．\n",
    "（とはいえ，実際にボクセルをメッシュに変換するプログラムの中では回転・反転操作を施したメッシュを区別するため全$256$通りを試すことになります．）\n",
    "仮にボクセルの頂点が物体の外側にある場合の値を$1$，内側にある場合の値を$0$としたときに，\n",
    "辺の両端の頂点の持つ値が異なるようなボクセルの辺上にメッシュの頂点が存在することになります．\n",
    "ここで，TSDF値は各ボクセルと物体表面との距離を表すため，ボクセルの頂点の値は２値ではなく，（メッシュとの近さを表す）連続値として算出することができます．\n",
    "この値に基づいて線形補間することで，メッシュ頂点の座標を決定します．\n",
    "\n",
    "では，先程取得したTSDFデータ`volume`からメッシュデータを作成し，描画してみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract a triangle mesh from the volume and visualize it.\n"
     ]
    }
   ],
   "source": [
    "print(\"Extract a triangle mesh from the volume and visualize it.\")\n",
    "mesh = volume.extract_triangle_mesh()\n",
    "mesh.compute_vertex_normals()\n",
    "o3d.visualization.draw_geometries([mesh],\n",
    "                                  front=[0.5297, -0.1873, -0.8272],\n",
    "                                  lookat=[2.0712, 2.0312, 1.7251],\n",
    "                                  up=[-0.0558, -0.9809, 0.1864],\n",
    "                                  zoom=0.47)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記を実行すると，作成されたメッシュデータが描画されます．\n",
    "マーチングキューブ法によるメッシュデータの作成は上記の2行目で行われています．\n",
    "\n",
    "最後に，作成されたメッシュデータから点群データをサンプリングし，表示させてみましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract a point cloud from the mesh and visualize it.\n"
     ]
    }
   ],
   "source": [
    "print(\"Extract a point cloud from the mesh and visualize it.\")\n",
    "pcd = mesh.sample_points_uniformly(number_of_points=10000)\n",
    "o3d.visualization.draw_geometries([pcd],\n",
    "                                  front=[0.5297, -0.1873, -0.8272],\n",
    "                                  lookat=[2.0712, 2.0312, 1.7251],\n",
    "                                  up=[-0.0558, -0.9809, 0.1864],\n",
    "                                  zoom=0.47)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のプログラムを実行すると，抽出された点群データが描画されます．\n",
    "なお，今回の例では`sample_points_uniformly()`という関数を使用しましたが，これは各メッシュ上の点を（メッシュの面積に比例した個数だけ）ランダムサンプリングするという単純なアルゴリズムを用いています．\n",
    "他にも，たとえばPoisson Disk Samplingというサンプリング手法を使う選択肢もあります．\n",
    "これを用いることで，空間的均一性の高い点群データを得ることができます．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
