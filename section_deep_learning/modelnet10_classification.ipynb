{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from torch_geometric.datasets import ModelNet\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "current_path = Path.cwd()\n",
    "dataset_dir = current_path / \"modelnet10\"\n",
    "\n",
    "pre_transform = T.Compose([\n",
    "    T.SamplePoints(1024, remove_faces=True, include_normals=False),\n",
    "    T.NormalizeScale(),\n",
    "])\n",
    "\n",
    "train_dataset = ModelNet(dataset_dir, name=\"10\", train=True, transform=None, pre_transform=pre_transform, pre_filter=None)\n",
    "test_dataset = ModelNet(dataset_dir, name=\"10\", train=False, transform=None, pre_transform=pre_transform, pre_filter=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train_dataset len:\", len(train_dataset))\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset[0].pos.shape)\n",
    "print(train_dataset[0].pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader as DataLoader\n",
    "dataloader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "batch = next(iter(dataloader))\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[32768], pos=[32768, 3], y=[32])\n",
      "torch.Size([32, 512])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import global_max_pool\n",
    "import torch.nn as nn\n",
    "\n",
    "class SymmFunction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SymmFunction, self).__init__()\n",
    "        self.shared_mlp = nn.Sequential(\n",
    "            nn.Linear(3, 64), nn.BatchNorm1d(64), nn.ReLU(),\n",
    "            nn.Linear(64, 128), nn.BatchNorm1d(128), nn.ReLU(),\n",
    "            nn.Linear(128, 512),\n",
    "        )\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        x = self.shared_mlp(batch.pos)\n",
    "        x = global_max_pool(x, batch.batch)\n",
    "        return x\n",
    "\n",
    "f = SymmFunction()\n",
    "print(batch)\n",
    "y = f(batch)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InputTNet, self).__init__()\n",
    "        self.input_mlp = nn.Sequential(\n",
    "            nn.Linear(3, 64), nn.BatchNorm1d(64), nn.ReLU(),\n",
    "            nn.Linear(64, 128), nn.BatchNorm1d(128), nn.ReLU(),\n",
    "            nn.Linear(128, 1024), nn.BatchNorm1d(1024), nn.ReLU(),\n",
    "        )\n",
    "        self.output_mlp = nn.Sequential(\n",
    "            nn.Linear(1024, 512), nn.BatchNorm1d(512), nn.ReLU(),\n",
    "            nn.Linear(512, 256), nn.BatchNorm1d(256), nn.ReLU(),\n",
    "            nn.Linear(256, 9)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, batch):\n",
    "        x = self.input_mlp(x)\n",
    "        x = global_max_pool(x, batch)\n",
    "        x = self.output_mlp(x)\n",
    "        x = x.view(-1, 3, 3)\n",
    "        id_matrix = torch.eye(3).to(x.device).view(1, 3, 3).repeat(x.shape[0], 1, 1)\n",
    "        x = id_matrix + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureTNet, self).__init__()\n",
    "        self.input_mlp = nn.Sequential(\n",
    "            nn.Linear(64, 64), nn.BatchNorm1d(64), nn.ReLU(),\n",
    "            nn.Linear(64, 128), nn.BatchNorm1d(128), nn.ReLU(),\n",
    "            nn.Linear(128, 1024), nn.BatchNorm1d(1024), nn.ReLU(),\n",
    "        )\n",
    "        self.output_mlp = nn.Sequential(\n",
    "            nn.Linear(1024, 512), nn.BatchNorm1d(512), nn.ReLU(),\n",
    "            nn.Linear(512, 256), nn.BatchNorm1d(256), nn.ReLU(),\n",
    "            nn.Linear(256, 64*64)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, batch):\n",
    "        x = self.input_mlp(x)\n",
    "        x = global_max_pool(x, batch)\n",
    "        x = self.output_mlp(x)\n",
    "        x = x.view(-1, 64, 64)\n",
    "        id_matrix = torch.eye(64).to(x.device).view(1, 64, 64).repeat(x.shape[0], 1, 1)\n",
    "        x = id_matrix + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNetClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PointNetClassification, self).__init__()\n",
    "        self.input_tnet = InputTNet()\n",
    "        self.mlp1 = nn.Sequential(\n",
    "            nn.Linear(3, 64), nn.BatchNorm1d(64), nn.ReLU(),\n",
    "            nn.Linear(64, 64), nn.BatchNorm1d(64), nn.ReLU(),\n",
    "        )\n",
    "        self.feature_tnet = FeatureTNet()\n",
    "        self.mlp2 = nn.Sequential(\n",
    "            nn.Linear(64, 64), nn.BatchNorm1d(64), nn.ReLU(),\n",
    "            nn.Linear(64, 128), nn.BatchNorm1d(128), nn.ReLU(),\n",
    "            nn.Linear(128, 1024), nn.BatchNorm1d(1024), nn.ReLU(),\n",
    "        )\n",
    "        self.mlp3 = nn.Sequential(\n",
    "            nn.Linear(1024, 512), nn.BatchNorm1d(512), nn.ReLU(), nn.Dropout(p=0.3),\n",
    "            nn.Linear(512, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(p=0.3),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, batch_data):\n",
    "        x = batch_data.pos\n",
    "        \n",
    "        input_transform = self.input_tnet(x, batch_data.batch)\n",
    "        transform = input_transform[batch_data.batch, :, :]\n",
    "        x = torch.bmm(transform, x.view(-1, 3, 1)).view(-1, 3)\n",
    "        \n",
    "        x = self.mlp1(x)\n",
    "        \n",
    "        feature_transform = self.feature_tnet(x, batch_data.batch)\n",
    "        transform = feature_transform[batch_data.batch, :, :]\n",
    "        x = torch.bmm(transform, x.view(-1, 64, 1)).view(-1, 64)\n",
    "\n",
    "        x = self.mlp2(x)        \n",
    "        x = global_max_pool(x, batch_data.batch)\n",
    "        x = self.mlp3(x)\n",
    "        \n",
    "        return x, input_transform, feature_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "num_epoch = 400\n",
    "batch_size = 32\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = PointNetClassification()\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(lr=1e-4, params=model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=num_epoch // 4, gamma=0.5)\n",
    "\n",
    "log_dir = current_path / \"log_modelnet10_classification\"\n",
    "log_dir.mkdir(exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "criteria = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/400 [00:00<?, ?it/s]\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/125 [00:00<01:05,  1.90it/s]\u001b[A\n",
      "  2%|▏         | 2/125 [00:00<00:50,  2.45it/s]\u001b[A\n",
      "  2%|▏         | 3/125 [00:00<00:39,  3.13it/s]\u001b[A\n",
      "  3%|▎         | 4/125 [00:00<00:31,  3.83it/s]\u001b[A\n",
      "  4%|▍         | 5/125 [00:01<00:26,  4.55it/s]\u001b[A\n",
      "  5%|▍         | 6/125 [00:01<00:22,  5.25it/s]\u001b[A\n",
      "  6%|▌         | 7/125 [00:01<00:20,  5.90it/s]\u001b[A\n",
      "  6%|▋         | 8/125 [00:01<00:18,  6.40it/s]\u001b[A\n",
      "  7%|▋         | 9/125 [00:01<00:17,  6.82it/s]\u001b[A\n",
      "  8%|▊         | 10/125 [00:01<00:16,  7.12it/s]\u001b[A\n",
      "  9%|▉         | 11/125 [00:01<00:15,  7.45it/s]\u001b[A\n",
      " 10%|▉         | 12/125 [00:01<00:14,  7.65it/s]\u001b[A\n",
      " 10%|█         | 13/125 [00:02<00:14,  7.78it/s]\u001b[A\n",
      " 11%|█         | 14/125 [00:02<00:14,  7.83it/s]\u001b[A\n",
      " 12%|█▏        | 15/125 [00:02<00:13,  8.08it/s]\u001b[A\n",
      " 13%|█▎        | 16/125 [00:02<00:13,  8.08it/s]\u001b[A\n",
      " 14%|█▎        | 17/125 [00:02<00:13,  8.09it/s]\u001b[A\n",
      " 14%|█▍        | 18/125 [00:02<00:13,  8.07it/s]\u001b[A\n",
      " 15%|█▌        | 19/125 [00:02<00:13,  8.02it/s]\u001b[A\n",
      " 16%|█▌        | 20/125 [00:02<00:13,  8.05it/s]\u001b[A\n",
      " 17%|█▋        | 21/125 [00:02<00:12,  8.03it/s]\u001b[A\n",
      " 18%|█▊        | 22/125 [00:03<00:12,  8.03it/s]\u001b[A\n",
      " 18%|█▊        | 23/125 [00:03<00:12,  8.04it/s]\u001b[A\n",
      " 19%|█▉        | 24/125 [00:03<00:12,  8.02it/s]\u001b[A\n",
      " 20%|██        | 25/125 [00:03<00:12,  8.06it/s]\u001b[A\n",
      " 21%|██        | 26/125 [00:03<00:12,  8.06it/s]\u001b[A\n",
      " 22%|██▏       | 27/125 [00:03<00:12,  8.02it/s]\u001b[A\n",
      " 22%|██▏       | 28/125 [00:03<00:12,  8.00it/s]\u001b[A\n",
      " 23%|██▎       | 29/125 [00:03<00:12,  7.98it/s]\u001b[A\n",
      " 24%|██▍       | 30/125 [00:04<00:11,  8.03it/s]\u001b[A\n",
      " 25%|██▍       | 31/125 [00:04<00:11,  8.05it/s]\u001b[A\n",
      " 26%|██▌       | 32/125 [00:04<00:11,  8.25it/s]\u001b[A\n",
      " 26%|██▋       | 33/125 [00:04<00:11,  8.21it/s]\u001b[A\n",
      " 27%|██▋       | 34/125 [00:04<00:11,  8.20it/s]\u001b[A\n",
      " 28%|██▊       | 35/125 [00:04<00:10,  8.36it/s]\u001b[A\n",
      " 29%|██▉       | 36/125 [00:04<00:10,  8.30it/s]\u001b[A\n",
      " 30%|██▉       | 37/125 [00:04<00:10,  8.26it/s]\u001b[A\n",
      " 30%|███       | 38/125 [00:05<00:10,  8.23it/s]\u001b[A\n",
      " 31%|███       | 39/125 [00:05<00:10,  8.21it/s]\u001b[A\n",
      " 32%|███▏      | 40/125 [00:05<00:10,  8.19it/s]\u001b[A\n",
      " 33%|███▎      | 41/125 [00:05<00:10,  8.34it/s]\u001b[A\n",
      " 34%|███▎      | 42/125 [00:05<00:09,  8.31it/s]\u001b[A\n",
      " 34%|███▍      | 43/125 [00:05<00:09,  8.30it/s]\u001b[A\n",
      " 35%|███▌      | 44/125 [00:05<00:09,  8.27it/s]\u001b[A\n",
      " 36%|███▌      | 45/125 [00:05<00:09,  8.25it/s]\u001b[A\n",
      " 37%|███▋      | 46/125 [00:06<00:09,  8.22it/s]\u001b[A\n",
      " 38%|███▊      | 47/125 [00:06<00:09,  8.34it/s]\u001b[A\n",
      " 38%|███▊      | 48/125 [00:06<00:09,  8.48it/s]\u001b[A\n",
      " 39%|███▉      | 49/125 [00:06<00:08,  8.58it/s]\u001b[A\n",
      " 40%|████      | 50/125 [00:06<00:08,  8.66it/s]\u001b[A\n",
      " 41%|████      | 51/125 [00:06<00:08,  8.71it/s]\u001b[A\n",
      " 42%|████▏     | 52/125 [00:06<00:08,  8.75it/s]\u001b[A\n",
      " 42%|████▏     | 53/125 [00:06<00:08,  8.76it/s]\u001b[A\n",
      " 43%|████▎     | 54/125 [00:06<00:08,  8.77it/s]\u001b[A\n",
      " 44%|████▍     | 55/125 [00:07<00:07,  8.78it/s]\u001b[A\n",
      " 45%|████▍     | 56/125 [00:07<00:07,  8.78it/s]\u001b[A\n",
      " 46%|████▌     | 57/125 [00:07<00:07,  8.78it/s]\u001b[A\n",
      " 46%|████▋     | 58/125 [00:07<00:07,  8.78it/s]\u001b[A\n",
      " 47%|████▋     | 59/125 [00:07<00:07,  8.78it/s]\u001b[A\n",
      " 48%|████▊     | 60/125 [00:07<00:07,  8.79it/s]\u001b[A\n",
      " 49%|████▉     | 61/125 [00:07<00:07,  8.78it/s]\u001b[A\n",
      " 50%|████▉     | 62/125 [00:07<00:07,  8.78it/s]\u001b[A\n",
      " 50%|█████     | 63/125 [00:07<00:07,  8.78it/s]\u001b[A\n",
      " 51%|█████     | 64/125 [00:08<00:07,  8.47it/s]\u001b[A\n",
      " 52%|█████▏    | 65/125 [00:08<00:07,  8.38it/s]\u001b[A\n",
      " 53%|█████▎    | 66/125 [00:08<00:07,  8.29it/s]\u001b[A\n",
      " 54%|█████▎    | 67/125 [00:08<00:06,  8.41it/s]\u001b[A\n",
      " 54%|█████▍    | 68/125 [00:08<00:06,  8.34it/s]\u001b[A\n",
      " 55%|█████▌    | 69/125 [00:08<00:06,  8.18it/s]\u001b[A\n",
      " 56%|█████▌    | 70/125 [00:08<00:06,  8.34it/s]\u001b[A\n",
      " 57%|█████▋    | 71/125 [00:08<00:06,  8.28it/s]\u001b[A\n",
      " 58%|█████▊    | 72/125 [00:09<00:06,  8.40it/s]\u001b[A\n",
      " 58%|█████▊    | 73/125 [00:09<00:06,  8.32it/s]\u001b[A\n",
      " 59%|█████▉    | 74/125 [00:09<00:06,  8.25it/s]\u001b[A\n",
      " 60%|██████    | 75/125 [00:09<00:06,  8.21it/s]\u001b[A\n",
      " 61%|██████    | 76/125 [00:09<00:05,  8.37it/s]\u001b[A\n",
      " 62%|██████▏   | 77/125 [00:09<00:05,  8.29it/s]\u001b[A\n",
      " 62%|██████▏   | 78/125 [00:09<00:05,  8.41it/s]\u001b[A\n",
      " 63%|██████▎   | 79/125 [00:09<00:05,  8.34it/s]\u001b[A\n",
      " 64%|██████▍   | 80/125 [00:10<00:05,  8.18it/s]\u001b[A\n",
      " 65%|██████▍   | 81/125 [00:10<00:05,  8.07it/s]\u001b[A\n",
      " 66%|██████▌   | 82/125 [00:10<00:05,  7.98it/s]\u001b[A\n",
      " 66%|██████▋   | 83/125 [00:10<00:05,  8.18it/s]\u001b[A\n",
      " 67%|██████▋   | 84/125 [00:10<00:05,  8.16it/s]\u001b[A\n",
      " 68%|██████▊   | 85/125 [00:10<00:04,  8.20it/s]\u001b[A\n",
      " 69%|██████▉   | 86/125 [00:10<00:04,  8.16it/s]\u001b[A\n",
      " 70%|██████▉   | 87/125 [00:10<00:04,  8.14it/s]\u001b[A\n",
      " 70%|███████   | 88/125 [00:11<00:04,  8.12it/s]\u001b[A\n",
      " 71%|███████   | 89/125 [00:11<00:04,  8.27it/s]\u001b[A\n",
      " 72%|███████▏  | 90/125 [00:11<00:04,  8.20it/s]\u001b[A\n",
      " 73%|███████▎  | 91/125 [00:11<00:04,  8.18it/s]\u001b[A\n",
      " 74%|███████▎  | 92/125 [00:11<00:04,  8.15it/s]\u001b[A\n",
      " 74%|███████▍  | 93/125 [00:11<00:03,  8.12it/s]\u001b[A\n",
      " 75%|███████▌  | 94/125 [00:11<00:03,  8.29it/s]\u001b[A\n",
      " 76%|███████▌  | 95/125 [00:11<00:03,  8.23it/s]\u001b[A\n",
      " 77%|███████▋  | 96/125 [00:12<00:03,  8.20it/s]\u001b[A\n",
      " 78%|███████▊  | 97/125 [00:12<00:03,  8.19it/s]\u001b[A\n",
      " 78%|███████▊  | 98/125 [00:12<00:03,  8.33it/s]\u001b[A\n",
      " 79%|███████▉  | 99/125 [00:12<00:03,  8.28it/s]\u001b[A\n",
      " 80%|████████  | 100/125 [00:12<00:03,  8.21it/s]\u001b[A\n",
      " 81%|████████  | 101/125 [00:12<00:02,  8.18it/s]\u001b[A\n",
      " 82%|████████▏ | 102/125 [00:12<00:02,  8.15it/s]\u001b[A\n",
      " 82%|████████▏ | 103/125 [00:12<00:02,  8.12it/s]\u001b[A\n",
      " 83%|████████▎ | 104/125 [00:12<00:02,  8.11it/s]\u001b[A\n",
      " 84%|████████▍ | 105/125 [00:13<00:02,  8.16it/s]\u001b[A\n",
      " 85%|████████▍ | 106/125 [00:13<00:02,  8.29it/s]\u001b[A\n",
      " 86%|████████▌ | 107/125 [00:13<00:02,  8.21it/s]\u001b[A\n",
      " 86%|████████▋ | 108/125 [00:13<00:02,  8.18it/s]\u001b[A\n",
      " 87%|████████▋ | 109/125 [00:13<00:01,  8.16it/s]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5aca96b221f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mthis_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mpred_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mtrue_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-26bde35f27e5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batch_data)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0minput_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_tnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_transform\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-84ef9b3e5082>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, batch)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_max_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mid_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in tqdm(range(num_epoch)):\n",
    "    model = model.train()\n",
    "    \n",
    "    losses = []\n",
    "    for batch_data in tqdm(train_dataloader, total=len(train_dataloader)):\n",
    "        batch_data = batch_data.to(device)\n",
    "        this_batch_size = batch_data.batch.detach().max() + 1\n",
    "        \n",
    "        pred_y, _, feature_transform = model(batch_data)\n",
    "        true_y = batch_data.y.detach()\n",
    "\n",
    "        class_loss = criteria(pred_y, true_y)\n",
    "        accuracy = float((pred_y.argmax(dim=1) == true_y).sum()) / float(this_batch_size)\n",
    "\n",
    "        id_matrix = torch.eye(feature_transform.shape[1]).to(feature_transform.device).view(1, 64, 64).repeat(feature_transform.shape[0], 1, 1)\n",
    "        transform_norm = torch.norm(torch.bmm(feature_transform, feature_transform.transpose(1, 2)) - id_matrix, dim=(1, 2))\n",
    "        reg_loss = transform_norm.mean()\n",
    "\n",
    "        loss = class_loss + reg_loss * 0.001\n",
    "        \n",
    "        losses.append({\n",
    "            \"loss\": loss.item(),\n",
    "            \"class_loss\": class_loss.item(),\n",
    "            \"reg_loss\": reg_loss.item(),\n",
    "            \"accuracy\": accuracy,\n",
    "            \"seen\": float(this_batch_size)})\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "    if (epoch % 10 == 0):\n",
    "        model_path = log_dir / f\"model_{epoch:06}.pth\"\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    loss = 0\n",
    "    class_loss = 0\n",
    "    reg_loss = 0\n",
    "    accuracy = 0\n",
    "    seen = 0\n",
    "    for d in losses:\n",
    "        seen = seen + d[\"seen\"]\n",
    "        loss = loss + d[\"loss\"] * d[\"seen\"]\n",
    "        class_loss = class_loss + d[\"class_loss\"] * d[\"seen\"]\n",
    "        reg_loss = reg_loss + d[\"reg_loss\"] * d[\"seen\"]\n",
    "        accuracy = accuracy + d[\"accuracy\"] * d[\"seen\"]\n",
    "    loss = loss / seen\n",
    "    class_loss = class_loss / seen\n",
    "    reg_loss = reg_loss / seen\n",
    "    accuracy = accuracy / seen\n",
    "    writer.add_scalar(\"train_epoch/loss\", loss, epoch)\n",
    "    writer.add_scalar(\"train_epoch/class_loss\", class_loss, epoch)\n",
    "    writer.add_scalar(\"train_epoch/reg_loss\", reg_loss, epoch)\n",
    "    writer.add_scalar(\"train_epoch/accuracy\", accuracy, epoch)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model = model.eval()\n",
    "\n",
    "        losses = []\n",
    "        for batch_data in tqdm(test_dataloader, total=len(test_dataloader)):\n",
    "            batch_data = batch_data.to(device)\n",
    "            this_batch_size = batch_data.batch.detach().max() + 1\n",
    "\n",
    "            pred_y, _, feature_transform = model(batch_data)\n",
    "            true_y = batch_data.y.detach()\n",
    "\n",
    "            class_loss = criteria(pred_y, true_y)\n",
    "            accuracy =float((pred_y.argmax(dim=1) == true_y).sum()) / float(this_batch_size)\n",
    "\n",
    "            id_matrix = torch.eye(feature_transform.shape[1]).to(feature_transform.device).view(1, 64, 64).repeat(feature_transform.shape[0], 1, 1)\n",
    "            transform_norm = torch.norm(torch.bmm(feature_transform, feature_transform.transpose(1, 2)) - id_matrix, dim=(1, 2))\n",
    "            reg_loss = transform_norm.mean()\n",
    "\n",
    "            loss = class_loss + reg_loss * 0.001\n",
    "\n",
    "            losses.append({\n",
    "                \"loss\": loss.item(),\n",
    "                \"class_loss\": class_loss.item(),\n",
    "                \"reg_loss\": reg_loss.item(),\n",
    "                \"accuracy\": accuracy,\n",
    "                \"seen\": float(this_batch_size)})\n",
    "            \n",
    "        loss = 0\n",
    "        class_loss = 0\n",
    "        reg_loss = 0\n",
    "        accuracy = 0\n",
    "        seen = 0\n",
    "        for d in losses:\n",
    "            seen = seen + d[\"seen\"]\n",
    "            loss = loss + d[\"loss\"] * d[\"seen\"]\n",
    "            class_loss = class_loss + d[\"class_loss\"] * d[\"seen\"]\n",
    "            reg_loss = reg_loss + d[\"reg_loss\"] * d[\"seen\"]\n",
    "            accuracy = accuracy + d[\"accuracy\"] * d[\"seen\"]\n",
    "        loss = loss / seen\n",
    "        class_loss = class_loss / seen\n",
    "        reg_loss = reg_loss / seen\n",
    "        accuracy = accuracy / seen\n",
    "        writer.add_scalar(\"test_epoch/loss\", loss, epoch)\n",
    "        writer.add_scalar(\"test_epoch/class_loss\", class_loss, epoch)\n",
    "        writer.add_scalar(\"test_epoch/reg_loss\", reg_loss, epoch)\n",
    "        writer.add_scalar(\"test_epoch/accuracy\", accuracy, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[32768], pos=[32768, 3], y=[32])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/opt/conda/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from torch_geometric.datasets import ModelNet\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader as DataLoader\n",
    "from torch_geometric.nn import global_max_pool\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = Path.cwd()\n",
    "dataset_dir = current_path / \"modelnet10\"\n",
    "log_dir = current_path / \"log_modelnet10_classification\"\n",
    "\n",
    "log_dir.mkdir(exist_ok=True)\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_transform = T.Compose([\n",
    "    T.SamplePoints(1024, remove_faces=True, include_normals=False),\n",
    "    T.NormalizeScale(),\n",
    "])\n",
    "\n",
    "train_dataset = ModelNet(dataset_dir, name=\"10\", train=True, transform=None, pre_transform=pre_transform, pre_filter=None)\n",
    "test_dataset = ModelNet(dataset_dir, name=\"10\", train=False, transform=None, pre_transform=pre_transform, pre_filter=None)\n",
    "\n",
    "dataset = train_dataset\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SymmFunction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SymmFunction, self).__init__()\n",
    "        self.input_mlp = nn.Sequential(\n",
    "            nn.Linear(3, 64), nn.BatchNorm1d(64), nn.ReLU(),\n",
    "            nn.Linear(64, 128), nn.BatchNorm1d(128), nn.ReLU(),\n",
    "            nn.Linear(128, 1024), nn.BatchNorm1d(1024),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, batch):\n",
    "        x = self.input_mlp(x)\n",
    "        x = global_max_pool(x, batch)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InputTNet, self).__init__()\n",
    "        self.input_mlp = nn.Sequential(\n",
    "            nn.Linear(3, 64), nn.BatchNorm1d(64), nn.ReLU(),\n",
    "            nn.Linear(64, 128), nn.BatchNorm1d(128), nn.ReLU(),\n",
    "            nn.Linear(128, 1024), nn.BatchNorm1d(1024), nn.ReLU(),\n",
    "        )\n",
    "        self.output_mlp = nn.Sequential(\n",
    "            nn.Linear(1024, 512), nn.BatchNorm1d(512), nn.ReLU(),\n",
    "            nn.Linear(512, 256), nn.BatchNorm1d(256), nn.ReLU(),\n",
    "            nn.Linear(256, 9)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, batch):\n",
    "        x = self.input_mlp(x)\n",
    "        x = global_max_pool(x, batch)\n",
    "        x = self.output_mlp(x)\n",
    "        x = x.view(-1, 3, 3)\n",
    "        id_matrix = torch.eye(3).to(x.device).view(1, 3, 3).repeat(x.shape[0], 1, 1)\n",
    "        x = id_matrix + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureTNet, self).__init__()\n",
    "        self.input_mlp = nn.Sequential(\n",
    "            nn.Linear(64, 64), nn.BatchNorm1d(64), nn.ReLU(),\n",
    "            nn.Linear(64, 128), nn.BatchNorm1d(128), nn.ReLU(),\n",
    "            nn.Linear(128, 1024), nn.BatchNorm1d(1024), nn.ReLU(),\n",
    "        )\n",
    "        self.output_mlp = nn.Sequential(\n",
    "            nn.Linear(1024, 512), nn.BatchNorm1d(512), nn.ReLU(),\n",
    "            nn.Linear(512, 256), nn.BatchNorm1d(256), nn.ReLU(),\n",
    "            nn.Linear(256, 64*64)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, batch):\n",
    "        x = self.input_mlp(x)\n",
    "        x = global_max_pool(x, batch)\n",
    "        x = self.output_mlp(x)\n",
    "        x = x.view(-1, 64, 64)\n",
    "        id_matrix = torch.eye(64).to(x.device).view(1, 64, 64).repeat(x.shape[0], 1, 1)\n",
    "        x = id_matrix + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNetClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PointNetClassification, self).__init__()\n",
    "        self.input_tnet = InputTNet()\n",
    "        self.mlp1 = nn.Sequential(\n",
    "            nn.Linear(3, 64), nn.BatchNorm1d(64), nn.ReLU(),\n",
    "            nn.Linear(64, 64), nn.BatchNorm1d(64), nn.ReLU(),\n",
    "        )\n",
    "        self.feature_tnet = FeatureTNet()\n",
    "        self.mlp2 = nn.Sequential(\n",
    "            nn.Linear(64, 64), nn.BatchNorm1d(64), nn.ReLU(),\n",
    "            nn.Linear(64, 128), nn.BatchNorm1d(128), nn.ReLU(),\n",
    "            nn.Linear(128, 1024), nn.BatchNorm1d(1024), nn.ReLU(),\n",
    "        )\n",
    "        self.mlp3 = nn.Sequential(\n",
    "            nn.Linear(1024, 512), nn.BatchNorm1d(512), nn.ReLU(), nn.Dropout(p=0.3),\n",
    "            nn.Linear(512, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(p=0.3),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, batch_data):\n",
    "        x = batch_data.pos\n",
    "        \n",
    "        input_transform = self.input_tnet(x, batch_data.batch)\n",
    "        transform = input_transform[batch_data.batch, :, :]\n",
    "        x = torch.bmm(transform, x.view(-1, 3, 1)).view(-1, 3)\n",
    "        \n",
    "        x = self.mlp1(x)\n",
    "        \n",
    "        feature_transform = self.feature_tnet(x, batch_data.batch)\n",
    "        transform = feature_transform[batch_data.batch, :, :]\n",
    "        x = torch.bmm(transform, x.view(-1, 64, 1)).view(-1, 64)\n",
    "\n",
    "        x = self.mlp2(x)        \n",
    "        x = global_max_pool(x, batch_data.batch)\n",
    "        x = self.mlp3(x)\n",
    "        \n",
    "        return x, input_transform, feature_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 400\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = PointNetClassification()\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(lr=1e-4, params=model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=num_epoch // 4, gamma=0.5)\n",
    "\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "#writer.close()\n",
    "\n",
    "pre_transform = T.Compose([\n",
    "    T.SamplePoints(1024, remove_faces=True, include_normals=False),\n",
    "    T.NormalizeScale(),\n",
    "])\n",
    "\n",
    "train_dataset = ModelNet(dataset_dir, name=\"10\", train=True, transform=None, pre_transform=pre_transform, pre_filter=None)\n",
    "test_dataset = ModelNet(dataset_dir, name=\"10\", train=False, transform=None, pre_transform=pre_transform, pre_filter=None)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "criteria = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [02:03<00:00,  1.97s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.61it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.60it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.53it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.53it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.60it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.61it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.61it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.62it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.61it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.60it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.62it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.60it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.89s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.61it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.63it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.63it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.63it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.60it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.62it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.62it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.89s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.62it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.60it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.60it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.62it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.60it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.53it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.62it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.53it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.53it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.60it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.60it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.64it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.63it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.60it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.62it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.62it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.60it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.53it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.62it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.60it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.62it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.63it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.62it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.60it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.60it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.53it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.62it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.53it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.63it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.60it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.59it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.63it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.60it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.57it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.52it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.54it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.56it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.58it/s]\n",
      "100%|██████████| 63/63 [01:59<00:00,  1.90s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n",
      "100%|██████████| 63/63 [01:50<00:00,  1.75s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.89it/s]\n",
      "100%|██████████| 63/63 [01:46<00:00,  1.69s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.91it/s]\n",
      "100%|██████████| 63/63 [01:46<00:00,  1.69s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.89it/s]\n",
      "100%|██████████| 63/63 [01:46<00:00,  1.69s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.86it/s]\n",
      "100%|██████████| 63/63 [01:46<00:00,  1.69s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.86it/s]\n",
      "100%|██████████| 63/63 [01:46<00:00,  1.69s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.87it/s]\n",
      "100%|██████████| 63/63 [01:46<00:00,  1.69s/it]\n",
      "100%|██████████| 15/15 [00:05<00:00,  2.89it/s]\n",
      "100%|██████████| 63/63 [01:44<00:00,  1.66s/it]\n",
      "100%|██████████| 15/15 [00:04<00:00,  3.27it/s]\n",
      "100%|██████████| 63/63 [01:33<00:00,  1.48s/it]\n",
      "100%|██████████| 15/15 [00:04<00:00,  3.30it/s]\n",
      "100%|██████████| 63/63 [01:33<00:00,  1.48s/it]\n",
      "100%|██████████| 15/15 [00:04<00:00,  3.30it/s]\n",
      "100%|██████████| 63/63 [01:33<00:00,  1.48s/it]\n",
      "100%|██████████| 15/15 [00:04<00:00,  3.37it/s]\n",
      "100%|██████████| 63/63 [01:33<00:00,  1.48s/it]\n",
      "100%|██████████| 15/15 [00:04<00:00,  3.39it/s]\n",
      "100%|██████████| 63/63 [01:33<00:00,  1.48s/it]\n",
      "100%|██████████| 15/15 [00:04<00:00,  3.30it/s]\n",
      "100%|██████████| 63/63 [01:33<00:00,  1.48s/it]\n",
      "100%|██████████| 15/15 [00:04<00:00,  3.31it/s]\n",
      "100%|██████████| 63/63 [01:33<00:00,  1.48s/it]\n",
      "100%|██████████| 15/15 [00:04<00:00,  3.31it/s]\n",
      "100%|██████████| 63/63 [01:33<00:00,  1.48s/it]\n",
      "100%|██████████| 15/15 [00:04<00:00,  3.29it/s]\n",
      "100%|██████████| 63/63 [01:33<00:00,  1.48s/it]\n",
      "100%|██████████| 15/15 [00:04<00:00,  3.32it/s]\n",
      "100%|██████████| 63/63 [01:29<00:00,  1.42s/it]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.23it/s]\n",
      "100%|██████████| 63/63 [01:06<00:00,  1.05s/it]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.77it/s]\n",
      "100%|██████████| 63/63 [01:06<00:00,  1.06s/it]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.75it/s]\n",
      "100%|██████████| 63/63 [01:06<00:00,  1.06s/it]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.70it/s]\n",
      "100%|██████████| 63/63 [01:06<00:00,  1.06s/it]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.79it/s]\n",
      "100%|██████████| 63/63 [01:06<00:00,  1.06s/it]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.72it/s]\n",
      "100%|██████████| 63/63 [01:06<00:00,  1.06s/it]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.69it/s]\n",
      "100%|██████████| 63/63 [01:06<00:00,  1.06s/it]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.68it/s]\n",
      "100%|██████████| 63/63 [01:06<00:00,  1.06s/it]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.74it/s]\n",
      "100%|██████████| 63/63 [01:06<00:00,  1.06s/it]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.71it/s]\n",
      "100%|██████████| 63/63 [01:06<00:00,  1.06s/it]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.72it/s]\n",
      "100%|██████████| 63/63 [01:06<00:00,  1.06s/it]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.72it/s]\n",
      "100%|██████████| 63/63 [01:06<00:00,  1.06s/it]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.74it/s]\n",
      "100%|██████████| 63/63 [01:06<00:00,  1.06s/it]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.71it/s]\n",
      "100%|██████████| 63/63 [01:06<00:00,  1.06s/it]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.79it/s]\n",
      "100%|██████████| 63/63 [01:06<00:00,  1.06s/it]\n",
      "100%|██████████| 15/15 [00:03<00:00,  4.74it/s]\n",
      "100%|██████████| 63/63 [01:04<00:00,  1.02s/it]\n",
      "100%|██████████| 15/15 [00:02<00:00,  5.86it/s]\n",
      "100%|██████████| 63/63 [00:34<00:00,  1.84it/s]\n",
      "100%|██████████| 15/15 [00:01<00:00, 12.50it/s]\n",
      "100%|██████████| 63/63 [00:27<00:00,  2.31it/s]\n",
      "100%|██████████| 15/15 [00:01<00:00, 12.67it/s]\n",
      "100%|██████████| 63/63 [00:27<00:00,  2.31it/s]\n",
      "100%|██████████| 15/15 [00:01<00:00, 12.57it/s]\n",
      "100%|██████████| 63/63 [00:27<00:00,  2.31it/s]\n",
      "100%|██████████| 15/15 [00:01<00:00, 12.54it/s]\n",
      "100%|██████████| 63/63 [00:24<00:00,  2.54it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 24.41it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.36it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 24.55it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.36it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.00it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.37it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.89it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.38it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.70it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.37it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.55it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.37it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 24.39it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.39it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.06it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.39it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.20it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.39it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.12it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.39it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.03it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.39it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 24.94it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.39it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.03it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.39it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.25it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.39it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.09it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.39it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.07it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.39it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.12it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.39it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.14it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.39it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.01it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.39it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.13it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.39it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.08it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.39it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.20it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.39it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.15it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.39it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.16it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.39it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 24.98it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.39it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.02it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.39it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.50it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.40it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.91it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.40it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.79it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.40it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 26.04it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.40it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.70it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.40it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.84it/s]\n",
      "100%|██████████| 63/63 [00:14<00:00,  4.40it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 25.98it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoch):\n",
    "#for epoch in tqdm(range(num_epoch)):\n",
    "    model = model.train()\n",
    "    \n",
    "    losses = []\n",
    "    for batch_data in tqdm(train_dataloader, total=len(train_dataloader)):\n",
    "        batch_data = batch_data.to(device)\n",
    "        this_batch_size = batch_data.batch.detach().max() + 1\n",
    "        \n",
    "        pred_y, _, feature_transform = model(batch_data)\n",
    "        true_y = batch_data.y.detach()\n",
    "\n",
    "        class_loss = criteria(pred_y, true_y)\n",
    "        accuracy = float((pred_y.argmax(dim=1) == true_y).sum()) / float(this_batch_size)\n",
    "\n",
    "        id_matrix = torch.eye(feature_transform.shape[1]).to(feature_transform.device).view(1, 64, 64).repeat(feature_transform.shape[0], 1, 1)\n",
    "        transform_norm = torch.norm(torch.bmm(feature_transform, feature_transform.transpose(1, 2)) - id_matrix, dim=(1, 2))\n",
    "        reg_loss = transform_norm.mean()\n",
    "\n",
    "        loss = class_loss + reg_loss * 0.001\n",
    "        \n",
    "        losses.append({\n",
    "            \"loss\": loss.item(),\n",
    "            \"class_loss\": class_loss.item(),\n",
    "            \"reg_loss\": reg_loss.item(),\n",
    "            \"accuracy\": accuracy,\n",
    "            \"seen\": float(this_batch_size)})\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "    if (epoch % 10 == 0):\n",
    "        model_path = log_dir / f\"model_{epoch:06}.pth\"\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    loss = 0\n",
    "    class_loss = 0\n",
    "    reg_loss = 0\n",
    "    accuracy = 0\n",
    "    seen = 0\n",
    "    for d in losses:\n",
    "        seen = seen + d[\"seen\"]\n",
    "        loss = loss + d[\"loss\"] * d[\"seen\"]\n",
    "        class_loss = class_loss + d[\"class_loss\"] * d[\"seen\"]\n",
    "        reg_loss = reg_loss + d[\"reg_loss\"] * d[\"seen\"]\n",
    "        accuracy = accuracy + d[\"accuracy\"] * d[\"seen\"]\n",
    "    loss = loss / seen\n",
    "    class_loss = class_loss / seen\n",
    "    reg_loss = reg_loss / seen\n",
    "    accuracy = accuracy / seen\n",
    "    writer.add_scalar(\"train_epoch/loss\", loss, epoch)\n",
    "    writer.add_scalar(\"train_epoch/class_loss\", class_loss, epoch)\n",
    "    writer.add_scalar(\"train_epoch/reg_loss\", reg_loss, epoch)\n",
    "    writer.add_scalar(\"train_epoch/accuracy\", accuracy, epoch)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model = model.eval()\n",
    "\n",
    "        losses = []\n",
    "        for batch_data in tqdm(test_dataloader, total=len(test_dataloader)):\n",
    "            batch_data = batch_data.to(device)\n",
    "            this_batch_size = batch_data.batch.detach().max() + 1\n",
    "\n",
    "            pred_y, _, feature_transform = model(batch_data)\n",
    "            true_y = batch_data.y.detach()\n",
    "\n",
    "            class_loss = criteria(pred_y, true_y)\n",
    "            accuracy =float((pred_y.argmax(dim=1) == true_y).sum()) / float(this_batch_size)\n",
    "\n",
    "            id_matrix = torch.eye(feature_transform.shape[1]).to(feature_transform.device).view(1, 64, 64).repeat(feature_transform.shape[0], 1, 1)\n",
    "            transform_norm = torch.norm(torch.bmm(feature_transform, feature_transform.transpose(1, 2)) - id_matrix, dim=(1, 2))\n",
    "            reg_loss = transform_norm.mean()\n",
    "\n",
    "            loss = class_loss + reg_loss * 0.001 * 0.001\n",
    "\n",
    "            losses.append({\n",
    "                \"loss\": loss.item(),\n",
    "                \"class_loss\": class_loss.item(),\n",
    "                \"reg_loss\": reg_loss.item(),\n",
    "                \"accuracy\": accuracy,\n",
    "                \"seen\": float(this_batch_size)})\n",
    "            \n",
    "        loss = 0\n",
    "        class_loss = 0\n",
    "        reg_loss = 0\n",
    "        accuracy = 0\n",
    "        seen = 0\n",
    "        for d in losses:\n",
    "            seen = seen + d[\"seen\"]\n",
    "            loss = loss + d[\"loss\"] * d[\"seen\"]\n",
    "            class_loss = class_loss + d[\"class_loss\"] * d[\"seen\"]\n",
    "            reg_loss = reg_loss + d[\"reg_loss\"] * d[\"seen\"]\n",
    "            accuracy = accuracy + d[\"accuracy\"] * d[\"seen\"]\n",
    "        loss = loss / seen\n",
    "        class_loss = class_loss / seen\n",
    "        reg_loss = reg_loss / seen\n",
    "        accuracy = accuracy / seen\n",
    "        writer.add_scalar(\"test_epoch/loss\", loss, epoch)\n",
    "        writer.add_scalar(\"test_epoch/class_loss\", class_loss, epoch)\n",
    "        writer.add_scalar(\"test_epoch/reg_loss\", reg_loss, epoch)\n",
    "        writer.add_scalar(\"test_epoch/accuracy\", accuracy, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred_y.argmax(dim=1) == true_y).sum().item() /2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.4300372302532196,\n",
       "  'class_loss': 0.4299507737159729,\n",
       "  'reg_loss': 86.45646667480469,\n",
       "  'accuracy': 0.859375,\n",
       "  'seen': 64.0},\n",
       " {'loss': 0.1293186992406845,\n",
       "  'class_loss': 0.12924015522003174,\n",
       "  'reg_loss': 78.54734802246094,\n",
       "  'accuracy': 0.984375,\n",
       "  'seen': 64.0},\n",
       " {'loss': 0.20876644551753998,\n",
       "  'class_loss': 0.20869794487953186,\n",
       "  'reg_loss': 68.50424194335938,\n",
       "  'accuracy': 0.9375,\n",
       "  'seen': 64.0},\n",
       " {'loss': 0.2231782227754593,\n",
       "  'class_loss': 0.2231127917766571,\n",
       "  'reg_loss': 65.43126678466797,\n",
       "  'accuracy': 0.953125,\n",
       "  'seen': 64.0},\n",
       " {'loss': 0.6764231324195862,\n",
       "  'class_loss': 0.6763547658920288,\n",
       "  'reg_loss': 68.35871887207031,\n",
       "  'accuracy': 0.796875,\n",
       "  'seen': 64.0},\n",
       " {'loss': 0.8635827302932739,\n",
       "  'class_loss': 0.8635047078132629,\n",
       "  'reg_loss': 77.99657440185547,\n",
       "  'accuracy': 0.734375,\n",
       "  'seen': 64.0},\n",
       " {'loss': 0.28232598304748535,\n",
       "  'class_loss': 0.28223732113838196,\n",
       "  'reg_loss': 88.67436981201172,\n",
       "  'accuracy': 0.90625,\n",
       "  'seen': 64.0},\n",
       " {'loss': 0.23369964957237244,\n",
       "  'class_loss': 0.2335999608039856,\n",
       "  'reg_loss': 99.68290710449219,\n",
       "  'accuracy': 0.953125,\n",
       "  'seen': 64.0},\n",
       " {'loss': 0.5144281983375549,\n",
       "  'class_loss': 0.5143374800682068,\n",
       "  'reg_loss': 90.71983337402344,\n",
       "  'accuracy': 0.78125,\n",
       "  'seen': 64.0},\n",
       " {'loss': 0.4027588963508606,\n",
       "  'class_loss': 0.4026842415332794,\n",
       "  'reg_loss': 74.65338134765625,\n",
       "  'accuracy': 0.890625,\n",
       "  'seen': 64.0},\n",
       " {'loss': 0.14427806437015533,\n",
       "  'class_loss': 0.14421714842319489,\n",
       "  'reg_loss': 60.915077209472656,\n",
       "  'accuracy': 0.984375,\n",
       "  'seen': 64.0},\n",
       " {'loss': 0.5337938666343689,\n",
       "  'class_loss': 0.5337226390838623,\n",
       "  'reg_loss': 71.2075424194336,\n",
       "  'accuracy': 0.765625,\n",
       "  'seen': 64.0},\n",
       " {'loss': 0.47959092259407043,\n",
       "  'class_loss': 0.4795230031013489,\n",
       "  'reg_loss': 67.91215515136719,\n",
       "  'accuracy': 0.78125,\n",
       "  'seen': 64.0},\n",
       " {'loss': 0.17334266006946564,\n",
       "  'class_loss': 0.17328250408172607,\n",
       "  'reg_loss': 60.15611267089844,\n",
       "  'accuracy': 0.953125,\n",
       "  'seen': 64.0},\n",
       " {'loss': 0.22115397453308105,\n",
       "  'class_loss': 0.22109580039978027,\n",
       "  'reg_loss': 58.17979049682617,\n",
       "  'accuracy': 0.9166666666666666,\n",
       "  'seen': 12.0}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
